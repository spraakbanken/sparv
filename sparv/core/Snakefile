"""Snakefile used by Snakemake."""
from pathlib import Path
import re

import snakemake
from snakemake.logging import logger

from sparv import util
from sparv.core import config as sparv_config
from sparv.core import paths, registry, snake_utils
from sparv.util.classes import *


# Remove Snakemake's default log handler
if config.get("run_by_sparv") and logger.log_handler and logger.log_handler[0] == logger.text_handler:
    logger.log_handler = []


# Don't do anything if no rule was specified
rule empty:
    shell:
        "echo"


# Init the storage for some essential variables
storage = snake_utils.SnakeStorage()


# ==============================================================================
# Dynamic Creation of Snakemake Rules
# ==============================================================================


def make_rule(module_name: str, f_name: str, annotator_info: dict, config_missing: bool = False) -> None:
    """Build Snakemake rules."""
    # Init rule storage
    rule_params = snake_utils.rule_helper(module_name, f_name, annotator_info, config, storage, config_missing)

    # Don't continue if this rule was skipped
    if rule_params:

        # Create rule for current annotation
        rule:
            message:
                "{}:{}".format(module_name, f_name)
            input:
                rule_params.inputs
            output:
                rule_params.outputs
            params:
                module_name = module_name,
                f_name = f_name,
                parameters = snake_utils.get_parameters(rule_params),
                log = config.get("log")
            script:
                "run_snake.py"
                # We don't use "run:" since the whole Snakefile would have to be reloaded for every single job,
                # due to how Snakemake creates processes for run-jobs.

        # Add to rule lists in storage
        snake_utils.add_to_storage(storage, rule_params, annotator_info)

        # Create rule to run this annotation on all input files

        # Get user-supplied wildcard values
        wildcards = dict(wc.split("=") for wc in config.get("wildcards", []))

        # Create rule, but only when called
        if rule_params.target_name in config.get("targets", []):
            @workflow.rule(name=rule_params.target_name)
            @workflow.input(expand([paths.annotation_dir / o
                                    if not (paths.annotation_dir in o.parents or paths.export_dir in o.parents)
                                    else o
                                    for o in rule_params.outputs], doc=config.get("doc")
                            or snake_utils.get_source_files(storage.source_files), **wildcards))
            @workflow.run
            def __rule__(*_args, **_kwargs):
                pass


# Find and load corpus config
config_missing = snake_utils.load_config(config)

# Find and load Sparv modules
registry.find_modules()

# Create rules for all available annotation functions
for module_name in registry.annotators:
    for f_name in registry.annotators[module_name]:
        annotator = registry.annotators[module_name][f_name]
        make_rule(module_name, f_name, annotator, config_missing)


# ==============================================================================
# Static Snakemake Rules
# ==============================================================================


# Rule to list all config options and their current values
rule config:
    run:
        if config.get("options"):
            out_conf = {}
            for k in config["options"]:
                out_conf[k] = sparv_config.get(k)
        else:
            out_conf = sparv_config.config
        print(snake_utils.prettify_config(out_conf))


# Rule to list all annotations
rule annotations:
    run:
        all_annotations = storage.all_annotations
        max_len = max(len(a[0]) for m in all_annotations for f in all_annotations[m]
                      for a in all_annotations[m][f]["annotations"]) + 4
        print()
        print("Available modules, annotators and annotations")
        print("=============================================\n")
        for module_name in sorted(all_annotations):
            print(util.Color.BOLD + "{}".format(module_name.upper()) + util.Color.RESET)
            for f_name in sorted(all_annotations[module_name]):
                print("      {}{}{}".format(util.Color.UNDERLINE, f_name, util.Color.RESET))
                f_desc = all_annotations[module_name][f_name]["description"]
                if f_desc:
                    print("      {}".format(f_desc))
                print()
                f_anns = all_annotations[module_name][f_name]["annotations"]
                for f_ann in sorted(f_anns):
                    print("        â€¢ {:{width}}{}".format(f_ann[0], f_ann[1] or "", width=max_len))
                    if f_ann[0].cls:
                        print(util.Color.ITALIC + "          <{}>".format(f_ann[0].cls) + util.Color.RESET)
                print()
            print("\n")

        max_len = max(len(cls) for cls in registry.annotation_classes["module_classes"]) + 8

        print("Available classes")
        print("=================\n")
        print(util.Color.BOLD + "    Classes defined by pipeline modules" + util.Color.RESET)
        print("        {}{:{}}    {}{}".format(util.Color.ITALIC, "Class", max_len, "Annotation", util.Color.RESET))
        for cls, anns in registry.annotation_classes["module_classes"].items():
            print("        {:{}}    {}".format(cls, max_len, anns[0]))
            if len(anns) > 1:
                for ann in anns[1:]:
                    print("        {:{}}    {}".format("", max_len, ann))

        if registry.annotation_classes["config_classes"]:
            print()
            print(util.Color.BOLD + "    Classes from config" + util.Color.RESET)
            print("        {}{:{}}    {}{}".format(util.Color.ITALIC, "Class", max_len, "Annotation", util.Color.RESET))
            for cls, ann in registry.annotation_classes["config_classes"].items():
                print("        {:{}}    {}".format(cls, max_len, ann))
        print()


# Rule to list all annotation presets
rule presets:
    run:
        resolved_presets = dict(
            (i, sparv_config.resolve_presets(sparv_config.presets[i])) for i in sparv_config.presets)
        print(snake_utils.prettify_config(resolved_presets))


# Rule to list all targets
rule list_targets:
    run:
        max_len = max(len(t[0]) for t in storage.named_targets + storage.export_targets
                      + storage.install_targets + storage.model_targets) + 4
        print()
        print("Available targets")
        print("=================\n")
        print("    EXPORTS")
        for target, desc, _lang in sorted(storage.export_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    INSTALLERS")
        for target, desc in sorted(storage.install_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    ANNOTATIONS")
        for target, desc in sorted(storage.named_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    MODEL BUILDERS")
        for target, desc, _lang in sorted(storage.model_targets):
            print("        {:{}}    {}".format(target, max_len, desc))


# Rule to list all exports
rule list_exports:
    run:
        max_len = max(len(t[0]) for t in storage.export_targets) + 4
        print()
        print("Available corpus output formats (exports)")
        print("=========================================")
        for target, desc, language in sorted(storage.export_targets):
            if not language or sparv_config.get("metadata.language") in language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Default: xml_export:pretty")
        print()


# Rule to list all input files
rule files:
    run:
        print("Available input files:\n")
        print(", ".join(snake_utils.get_source_files(storage.source_files)))


# Rule to remove annotations dir
rule clean:
    run:
        # Only run if corpus config is found in same dir
        if config_missing:
            print("No corpus config found. Not removing anything.")
        else:
            import shutil
            to_remove = []
            if config.get("export") or config.get("all"):
                to_remove.append(paths.export_dir)
                assert paths.export_dir, "Export dir name not configured."
            if config.get("all") or not config.get("export"):
                to_remove.append(paths.annotation_dir)
                assert paths.annotation_dir, "Annotations dir name not configured."

            something_removed = False
            for d in to_remove:
                full_path = Path.cwd() / d
                if full_path.is_dir():
                    shutil.rmtree(full_path)
                    print(d, "directory removed")
                    something_removed = True
            if not something_removed:
                print("Nothing to remove")


# Rule to list all installations that will be made when running `sparv install`
rule list_installs:
    run:
        max_len = max(len(t[0]) for t in storage.install_targets) + 4
        print()
        print("Installations to be made")
        print("========================")
        for target, desc in sorted(storage.install_targets):
            if target in sparv_config.get("korp.install", []):
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Other available installations")
        print("=============================")
        for target, desc in sorted(storage.install_targets):
            if target not in sparv_config.get("korp.install", []):
                print("    {:{}}    {}".format(target, max_len, desc))
        print()


# Rule for making installations
rule install_annotated_corpus:
    input:
        snake_utils.get_install_targets(storage.install_outputs)


# Rule to list all models that can be built/downloaded
rule list_models:
    run:
        max_len = max(len(t[0]) for t in storage.model_targets) + 4
        print()
        print("Models for current language ({})".format(sparv_config.get("metadata.language")))
        print("=================================")
        for target, desc, language in sorted(storage.model_targets):
            if language and sparv_config.get("metadata.language") in language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Language-independent models")
        print("===========================")
        for target, desc, language in sorted(storage.model_targets):
            if not language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()


# Build all models. Build even the non-optional ones if force_optional_models = True.
rule build_models:
    input:
        storage.model_outputs
